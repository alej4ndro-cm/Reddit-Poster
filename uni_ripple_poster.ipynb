{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and modules\n",
    "from docx import Document\n",
    "import praw\n",
    "import csv\n",
    "import time\n",
    "\n",
    "reddit_username = '' # Put your Reddit username\n",
    "reddit_password = '' # Put your Reddit password\n",
    "reddit_client_id = '' # Put your Reddit client ID info\n",
    "reddit_client_secret = '' # Put your Reddit client secret info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script that reads words from a list_of_universities.docx file and writes them to a .csv file, separated by commas:\n",
    "\n",
    "def convert_docx_to_csv(docx_path, csv_path):\n",
    "    # Load the Word document\n",
    "    doc = Document(docx_path)\n",
    "    \n",
    "    # Extract text from each paragraph and store in a list\n",
    "    lines = [p.text for p in doc.paragraphs if p.text.strip() != \"\"]\n",
    "    \n",
    "    # Write lines to CSV\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(lines)  # write lines as a single row\n",
    "\n",
    "# Usage\n",
    "convert_docx_to_csv('list_of_universities.docx', 'list_of_universities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header added and saved to universities_with_potential_subreddits_with_header.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the paths for the input and output CSV files\n",
    "input_csv_path = 'universities_with_potential_subreddits.csv'\n",
    "output_csv_path = 'universities_with_potential_subreddits_with_header.csv'\n",
    "\n",
    "# Define the header for the CSV\n",
    "header = ['University Name', 'Potential Subreddits']\n",
    "\n",
    "# Read the existing CSV and add a header row\n",
    "with open(input_csv_path, 'r') as input_file, open(output_csv_path, 'w', newline='') as output_file:\n",
    "    reader = csv.reader(input_file)\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # Add the header row to the new CSV\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Copy the data from the existing CSV to the new one\n",
    "    for row in reader:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Header added and saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
-      "Failed to post to Potential Subreddits for University Name. Reason: SUBREDDIT_NOEXIST: \"Hmm, that community doesn't exist. Try checking the spelling.\" on field 'sr'\n",
-      "Failed to post to Potential Subreddits for University. Reason: SUBREDDIT_NOEXIST: \"Hmm, that community doesn't exist. Try checking the spelling.\" on field 'sr'\n",
-      "Successfully posted to r/ABA for Abraham Baldwin Agricultural College\n",
-      "Successfully posted to r/AdamsState for Adams State University\n"
     ]
    }
   ],
   "source": [
    "# Parsing function\n",
    "def parse_csv(csv_path):\n",
    "    with open(csv_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        uni_subreddit_dict = {}\n",
    "        \n",
    "        for row in reader:\n",
    "            university = row[0]\n",
    "            subreddits = row[1]  # Store subreddits as a string\n",
    "            uni_subreddit_dict[university] = subreddits\n",
    "            \n",
    "        return uni_subreddit_dict\n",
    "\n",
    "# Read detailed content from the 'content.docx' file\n",
    "def read_detailed_content(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    content = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    return content\n",
    "\n",
    "# Initialize praw instance\n",
    "reddit = praw.Reddit(\n",
    "    client_id=f'{reddit_client_id}',\n",
    "    client_secret=f'{reddit_client_secret}',\n",
    "    password=f'{reddit_password}',\n",
    "    user_agent=f'python:UniRipplePoster:v1.0 (by /u/{reddit_username})',\n",
    "    username=f'{reddit_username}'\n",
    ")\n",
    "\n",
    "universities_with_subreddits = parse_csv('universities_with_potential_subreddits.csv')\n",
    "\n",
    "DELAY_BETWEEN_POSTS = 10  # delay of 10 seconds\n",
    "\n",
    "# Read detailed content from 'content.docx'\n",
    "detailed_content = read_detailed_content('content.docx')\n",
    "\n",
    "for university, subreddit_str in universities_with_subreddits.items():\n",
    "    subreddits = subreddit_str.strip(\"[]\").replace(\"'\", \"\").split(', ')\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        try:\n",
    "            # Construct the title and content of the post\n",
    "            title = f\"Join Ripplematch, {university} students!\"\n",
    "    \n",
    "            # Use the detailed content from 'content.docx' as the self-text\n",
    "            content = detailed_content\n",
    "    \n",
    "            # Post to the subreddit\n",
    "            reddit.subreddit(subreddit_name.strip()).submit(title, selftext=content)\n",
    "            \n",
    "            print(f\"Successfully posted to {subreddit_name.strip()} for {university}\")\n",
    "            \n",
    "            # Introduce delay\n",
    "            time.sleep(DELAY_BETWEEN_POSTS)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to post to {subreddit_name.strip()} for {university}. Reason: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
